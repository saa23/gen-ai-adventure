{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import IPython\n",
    "from dotenv import load_dotenv\n",
    "import os\n",
    "\n",
    "load_dotenv()\n",
    "openai_api_key = os.getenv(\"OPENAI_API_KEY\")\n",
    "\n",
    "client = OpenAI()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_completion(messages,  model=\"gpt-3.5-turbo\", temperature=0, max_tokens=300):\n",
    "    response = client.chat.completions.create(\n",
    "        model=model,\n",
    "        messages=messages,\n",
    "        temperature=temperature,\n",
    "        max_tokens=max_tokens,\n",
    "    )\n",
    "    return response.choices[0].message.content"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-1: Be Specific and Clear\n",
    "Write the instruction as clear  and specific as possible to get the desired LLM responses"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example-1: Not Clear Instruction\n",
    "User don't provide information about interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sorry, I couldn't find a movie to recommend today.\n"
     ]
    }
   ],
   "source": [
    "global_trending_movies = [\"The Suicide Squad\", \"No Time to Die\", \"Dune\",  \"Spider-Man: No Way Home\", \"The French Dispatch\", \"Black Widow\", \"Eternals\", \"The Matrix Resurrections\", \"West Side Story\", \"The Many Saints of Newark\"]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Your task is to recommend movies to a customer.\n",
    "You are responsible to recommend a movie from the top global trending movies from {global_trending_movies}.\n",
    "You should refrain from asking users for their preferences and avoid asking for personal information.\n",
    "If you don't have a movie to recommend or don't know the user interests, you should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "\"\"\"\n",
    "\n",
    "user_request = \"\"\"\n",
    "Please recommend a movie based on my interests.\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message.format(global_trending_movies=global_trending_movies)\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_request\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)\n",
    "\n",
    "# response format data\n",
    "# id='chatcmpl-8Ude3gtiwLSZ2rpizFjLLPY72YlCR', \n",
    "# choices=[\n",
    "#     Choice(\n",
    "#         finish_reason='stop', \n",
    "#         index=0, \n",
    "#         message=ChatCompletionMessage(\n",
    "#                 content=\"Sorry, I couldn't find a movie to recommend today.\",\n",
    "#                 role='assistant', \n",
    "#                 function_call=None, \n",
    "#                 tool_calls=None\n",
    "#                 )\n",
    "#             )\n",
    "#             ], \n",
    "# created=1702312927, \n",
    "# model='gpt-3.5-turbo-0613', \n",
    "# object='chat.completion', \n",
    "# system_fingerprint=None, \n",
    "# usage=CompletionUsage(\n",
    "#     completion_tokens=12, \n",
    "#     prompt_tokens=152, \n",
    "#     total_tokens=164\n",
    "#     )\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example-2: More Clear Instruction\n",
    "User provides information about interests."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Based on your interest in super-hero movies, I recommend you watch \"Spider-Man: No Way Home\". It is one of the top global trending movies and features the beloved superhero Spider-Man. Enjoy the movie!\n"
     ]
    }
   ],
   "source": [
    "global_trending_movies = [\"The Suicide Squad\", \"No Time to Die\", \"Dune\",  \"Spider-Man: No Way Home\", \"The French Dispatch\", \"Black Widow\", \"Eternals\", \"The Matrix Resurrections\", \"West Side Story\", \"The Many Saints of Newark\"]\n",
    "\n",
    "system_message = \"\"\"\n",
    "Your task is to recommend movies to a customer.\n",
    "You are responsible to recommend a movie from the top global trending movies from {global_trending_movies}.\n",
    "You should refrain from asking users for their preferences and avoid asking for personal information.\n",
    "If you don't have a movie to recommend or don't know the user interests, you should respond \"Sorry, couldn't find a movie to recommend today.\".\n",
    "\"\"\"\n",
    "\n",
    "user_request = \"\"\"\n",
    "I love super-hero movies. Please recommend a movie based on my interests.\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message.format(global_trending_movies=global_trending_movies)\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_request\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-2: Adding Delimiter\n",
    "Delimiter helps to better structure instructions and prompt components. It helps to get more reliable responses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```pythonstrings2 = []\n",
       "strings2.append(\"one\")\n",
       "strings2.append(\"two\")\n",
       "strings2.append(\"THREE\")\n",
       "strings2.append(\"4\")\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Convert the following code block in the #### <code> #### section to python:\n",
    "\n",
    "####\n",
    "strings2.push(\"one\")\n",
    "strings2.push(\"two\")\n",
    "strings2.push(\"THREE\")\n",
    "strings2.push(\"4\")\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "IPython.display.Markdown(\"```python\" + get_completion(message) + \"\\n```\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-3: Specify Output Format\n",
    "Better stated the format prompt response explicitly to get desired results. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{\n",
      "  \"product_name\": \"Nike Air Max 270 React\",\n",
      "  \"product_brand\": \"Nike\",\n",
      "  \"product_series_name\": \"Air Max\"\n",
      "}\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "Your task is:  given a product description, return the requested information in the section delimited by #### ####.\n",
    "Format the output as a JSON object.\n",
    "\n",
    "Product Description:\n",
    "Introducing the Nike Air Max 270 React: a comfortable and stylish sneaker that combines two of Nike's best technologies.\n",
    "With a sleek black design and a unique bubble sole, these shoes are perfect for everyday wear.\n",
    "\n",
    "####\n",
    "product_name: the name of the product\n",
    "product_brand: the name of the brand (if any)\n",
    "product_series_name: the name of the product series (if any)\n",
    "####\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "print(get_completion(message))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-4: Think Step by Step\n",
    "To acquire reasoning in LLMs, better instruct the model to think step by step.\n",
    "\n",
    "This style of prompt allows it to provide the details steps/ process before providing final answer/ response."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The odd numbers in the group are 15, 5, 13, 7, and 1. \n",
      "\n",
      "Adding them together: 15 + 5 + 13 + 7 + 1 = 41. \n",
      "\n",
      "The result, 41, is an odd number.\n"
     ]
    }
   ],
   "source": [
    "prompt = \"\"\"\n",
    "The odd numbers in this group add up to an even number: 15,32,5,13,82,7,1.\n",
    "\n",
    "Solve by breaking the problem into steps. First, identify the odd numbers, add them, and indicate whether the result is odd or even.\n",
    "\"\"\"\n",
    "\n",
    "message = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(message)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Case-5: Role Playing\n",
    "Apply role playing by combining system message,  user message, and assistant message.\n",
    "\n",
    "You can use and combine messages to guide the behavior you expect from the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Certainly! Black holes are formed from the remnants of massive stars that have undergone gravitational collapse. When a star exhausts its nuclear fuel, it can no longer support itself against its own gravity. The core of the star collapses under its own weight, leading to the formation of a black hole.\n",
      "\n",
      "The collapse is driven by the force of gravity, which becomes extremely strong as the star's mass is concentrated into a small volume. As the core collapses, it forms a singularity, a point of infinite density and zero volume. Surrounding the singularity is the event horizon, which is the boundary beyond which nothing, not even light, can escape the gravitational pull of the black hole.\n",
      "\n",
      "The formation of black holes is a fascinating and complex process, involving the interplay of gravity, nuclear physics, and general relativity. It is an active area of research in astrophysics and cosmology.\n"
     ]
    }
   ],
   "source": [
    "system_message = \"\"\"\n",
    "The following is a conversation with an AI research assistant. The assistant tone is technical and scientific.\n",
    "\"\"\"\n",
    "\n",
    "user_message_1 = \"\"\"\n",
    "Hello, who are you?\n",
    "\"\"\"\n",
    "\n",
    "ai_message_1 = \"\"\"\n",
    "Greeting! I am an AI research assistant. How can I help you today?\n",
    "\"\"\"\n",
    "\n",
    "prompt = \"\"\"\n",
    "Human: Can you tell me about the creation of blackholes?\n",
    "AI:\n",
    "\"\"\"\n",
    "\n",
    "messages = [\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": system_message\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": user_message_1\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"assistant\",\n",
    "        \"content\": ai_message_1\n",
    "\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\",\n",
    "        \"content\": prompt\n",
    "    }\n",
    "]\n",
    "\n",
    "response = get_completion(messages)\n",
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
